{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cf23bb-6dcf-4040-ae6d-e06bd86c7f36",
   "metadata": {},
   "source": [
    "Parse xml files to create positive and negative datasets with labels and boundary box information to train model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e79fe98-c3ec-4d62-817e-b4b7b6b5c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import xml.etree.ElementTree as ET\n",
    " \n",
    "import numpy as np\n",
    " \n",
    "def read_voc_xml(xmlfile: str) -> dict:\n",
    "    \"\"\"read the Pascal VOC XML and return (filename, object name, bounding box)\n",
    "    where bounding box is a vector of (xmin, ymin, xmax, ymax). The pixel\n",
    "    coordinates are 1-based.\n",
    "    \"\"\"\n",
    "    root = ET.parse(xmlfile).getroot()\n",
    "    boxes = {\"filename\": root.find(\"filename\").text,\n",
    "             \"objects\": []\n",
    "            }\n",
    "    for box in root.iter('object'):\n",
    "        bb = box.find('bndbox')\n",
    "        obj = {\n",
    "            \"name\": box.find('name').text,\n",
    "            \"xmin\": int(bb.find(\"xmin\").text),\n",
    "            \"ymin\": int(bb.find(\"ymin\").text),\n",
    "            \"xmax\": int(bb.find(\"xmax\").text),\n",
    "            \"ymax\": int(bb.find(\"ymax\").text),\n",
    "        }\n",
    "        boxes[\"objects\"].append(obj)\n",
    " \n",
    "    return boxes\n",
    " \n",
    "# Read Pascal VOC and write data\n",
    "base_path = pathlib.Path(\"dataset-iiit-pet-master\")\n",
    "img_src = base_path / \"images\"\n",
    "ann_src = base_path / \"annotations\" / \"xmls\"\n",
    " \n",
    "negative = []\n",
    "positive = []\n",
    "for xmlfile in ann_src.glob(\"*.xml\"):\n",
    "    # load xml\n",
    "    ann = read_voc_xml(str(xmlfile))\n",
    "    if ann['objects'][0]['name'] == 'cat':\n",
    "        # negative sample (cat)\n",
    "        negative.append(str(img_src / ann['filename']))\n",
    "    else:\n",
    "        # positive sample (dog)\n",
    "        bbox = []\n",
    "        for obj in ann['objects']:\n",
    "            x = obj['xmin']\n",
    "            y = obj['ymin']\n",
    "            w = obj['xmax'] - obj['xmin']\n",
    "            h = obj['ymax'] - obj['ymin']\n",
    "            bbox.append(f\"{x} {y} {w} {h}\")\n",
    "        line = f\"{str(img_src/ann['filename'])} {len(bbox)} {' '.join(bbox)}\"\n",
    "        positive.append(line)\n",
    " \n",
    "# write the output to `negative.dat` and `postiive.dat`\n",
    "with open(\"negative.dat\", \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(negative))\n",
    " \n",
    "with open(\"positive.dat\", \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(positive))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4b313-4dc6-45e2-9814-895321873625",
   "metadata": {},
   "source": [
    "Video Feed with Dog Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4078edba-64fa-4645-b2d4-944c3f7683d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "model = 'dog_detect/cascade.xml'\n",
    "classifier = cv2.CascadeClassifier(model)\n",
    "\n",
    "# need a VideoWriter object and codec for its parameter\n",
    "# codec specifies video format\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "                      # out file, code,  frame rate, resolution\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"ERROR: image not captured\")\n",
    "        break\n",
    "        \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform object detection\n",
    "    objects, reject_levels, level_weights = classifier.detectMultiScale3(gray,\n",
    "                                            scaleFactor=1.1, minNeighbors=50,\n",
    "                                            minSize=(50, 50), outputRejectLevels=True)\n",
    "    # for i in level_weights:\n",
    "    level_weights = np.array(level_weights)\n",
    "    best_guess = np.argmax(level_weights)\n",
    "    # Draw rectangles around detected objects\n",
    "    for confidence, (x, y, w, h) in zip(level_weights, objects):\n",
    "        if confidence >= 2.75 and confidence != np.max(level_weights):\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        if confidence >= 2.75 and confidence == np.max(level_weights):\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Cam Stream', frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    # cv2.waitKey(delay) returns ascii value of key pressed\n",
    "    # & 0xFF is bitwise operation to only get lowest 8 bits of key pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# print(level_weights[best_guess])\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f5b19-eb58-4eda-b72d-8c1fd98d3e51",
   "metadata": {},
   "source": [
    "Function to parse xml files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3f72dc-f86e-4750-a460-25075459f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_bbox_info(xmlfile):\n",
    "    # parse the XML file\n",
    "    root = ET.parse(xmlfile).getroot()\n",
    "\n",
    "    # iterate over <object> tag\n",
    "    obj = root.find('object')\n",
    "    # get animal tag\n",
    "    tag = obj.find('name').text\n",
    "    # ann['objects'][0]['name'] == 'cat'\n",
    "    # print(tag)\n",
    "    bndbox = obj.find('bndbox') # get the bounding box element\n",
    "\n",
    "    # extract bounding box coordinates\n",
    "    xmin = int(bndbox.find('xmin').text)\n",
    "    ymin = int(bndbox.find('ymin').text)\n",
    "    xmax = int(bndbox.find('xmax').text)\n",
    "    ymax = int(bndbox.find('ymax').text)\n",
    "        \n",
    "    return xmin, ymin, xmax, ymax, tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d01d66-8c40-4214-a5a9-0f880d671846",
   "metadata": {},
   "source": [
    "Function to calculate how much a detection box overlaps a boundary box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04e90691-c54b-4c2f-9c69-b04b454eaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes 2 arrays of values that 2 boundary boxes have in common. \n",
    "# They will calculate the area of the 2 boxes overlap and return the percentage of the bbox that is overlapped\n",
    "def percentage_overlap(xml_object, common_x, common_y):\n",
    "    # unpack bbox\n",
    "    xmin, ymin, xmax, ymax, tag = xml_object\n",
    "    # compute its area\n",
    "    bbox = (xmax - xmin) * (ymax - ymin)\n",
    "    # compute area that boxes have in common\n",
    "    detection_box = common_x.size * common_y.size\n",
    "\n",
    "    overlap = detection_box / bbox\n",
    "    # print(overlap)\n",
    "\n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb76bb-ab8b-4116-aca8-0176d538299e",
   "metadata": {},
   "source": [
    "Function that makes decisions on instances (images) and fills a confusion matrix with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30b24ee6-0a2a-4b36-a65f-917952add8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(matrix, xml, level_weights, objects, filename): \n",
    "    '''\n",
    "    matrix format is [TN, FP]\n",
    "                     [FN, TP]\n",
    "    '''\n",
    "    xmin, ymin, xmax, ymax, tag = get_bbox_info(xml)\n",
    "    xml_object = (xmin, ymin, xmax, ymax, tag)\n",
    "        \n",
    "    # converts into np array\n",
    "    level_weights = np.array(level_weights)\n",
    "    # only want boxes that are at least as confident as value\n",
    "    filtered_objects = []\n",
    "\n",
    "    # find width and length of boundary box\n",
    "    x_bbox_array = np.arange(xmin, xmax + 1)\n",
    "    y_bbox_array = np.arange(ymin, ymax + 1)\n",
    "\n",
    "    for confidence, (x, y, w, h) in zip(level_weights, objects):\n",
    "        if confidence >= 2.75:\n",
    "            filtered_objects.append((x, y, w, h))\n",
    "\n",
    "    # If filtered_objects is empty then can leave early\n",
    "    # False Negative\n",
    "    if len(filtered_objects) == 0 and tag == 'dog':\n",
    "        matrix[1][0] += 1\n",
    "        return\n",
    "    # True Negative\n",
    "    if len(filtered_objects) == 0 and tag == 'cat':\n",
    "        matrix[0][0] += 1\n",
    "        return\n",
    "            \n",
    "    # See if boxes overlap enough to count as a positive, filtered_objects are all objects model is confident is a dog      \n",
    "    for obj in filtered_objects:\n",
    "        # arrays whos lengths will be used to compare the area of 2 squares\n",
    "        # pixels are integers so can make array from x1 to x2 incrementing by one\n",
    "        x_detected_array = np.arange(x, (x + w + 1))\n",
    "        y_detected_array = np.arange(y, (y + h + 1))\n",
    "\n",
    "        common_x = np.intersect1d(x_bbox_array, x_detected_array)\n",
    "        common_y = np.intersect1d(y_bbox_array, y_detected_array)\n",
    "        overlap = percentage_overlap(xml_object, common_x, common_y)\n",
    "        \n",
    "        # True Positive\n",
    "        if overlap >= 0.25 and tag == 'dog':\n",
    "            matrix[1][1] += 1\n",
    "        # False Positive (might be part of dog but not dogs face)\n",
    "        elif (overlap < 0.25 and tag == 'dog') or (tag == 'cat'):\n",
    "            matrix[0][1] += 1\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88498ce7-1980-4ba4-a795-cf384050a9a4",
   "metadata": {},
   "source": [
    "Function that displays an image with the detection boxes and boundary box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "773c950f-fe41-4891-bf94-628bb80eeacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(img, xml, level_weights, objects): \n",
    "\n",
    "    xmin, ymin, xmax, ymax, tag = get_bbox_info(xml)\n",
    "    level_weights = np.array(level_weights)\n",
    "\n",
    "    # Draw boundary box\n",
    "    cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "    x_bbox_array = np.arange(xmin, xmax + 1)\n",
    "    y_bbox_array = np.arange(ymin, ymax + 1)\n",
    "    \n",
    "    # Draw rectangles around detected objects\n",
    "    for confidence, (x, y, w, h) in zip(level_weights, objects):\n",
    "        # arrays whos lengths will be used to compare the area of 2 squares\n",
    "        x_detected_array = np.arange(x, (x + w + 1))\n",
    "        y_detected_array = np.arange(y, (y + h + 1))\n",
    "        \n",
    "        if confidence >= 2.75:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f07163-ee69-4480-9d97-f7881f2b5b32",
   "metadata": {},
   "source": [
    "Function to calculate relavent performance metrics from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "314c1429-e185-4555-9d1f-3d7dc5c4befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(matrix):\n",
    "    TN = matrix[0][0]\n",
    "    FP = matrix[0][1]\n",
    "    FN = matrix[1][0]\n",
    "    TP = matrix[1][1]\n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / (TN + FP + FN + TP)\n",
    "    specificity = TN / (TN + FP) # True Negative Rate, ability to ID true negatives\n",
    "    f1_score =  2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, accuracy, specificity, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6925bba-515a-4821-bcad-11b6638e031f",
   "metadata": {},
   "source": [
    "Use trained model on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62a22a32-4ea6-49fc-96ff-b42bbffc8cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abyssinian_118.jpg\n",
      "Abyssinian_16.jpg\n",
      "Abyssinian_165.jpg\n",
      "Abyssinian_170.jpg\n",
      "Abyssinian_170.jpg\n",
      "Abyssinian_182.jpg\n",
      "Abyssinian_190.jpg\n",
      "american_bulldog_106.jpg\n",
      "american_bulldog_116.jpg\n",
      "american_bulldog_119.jpg\n",
      "american_bulldog_125.jpg\n",
      "american_bulldog_126.jpg\n",
      "american_bulldog_140.jpg\n",
      "american_bulldog_176.jpg\n",
      "american_bulldog_179.jpg\n",
      "american_bulldog_196.jpg\n",
      "american_bulldog_201.jpg\n",
      "american_bulldog_202.jpg\n",
      "american_pit_bull_terrier_10.jpg\n",
      "american_pit_bull_terrier_105.jpg\n",
      "basset_hound_129.jpg\n",
      "basset_hound_13.jpg\n",
      "basset_hound_134.jpg\n",
      "basset_hound_138.jpg\n",
      "basset_hound_142.jpg\n",
      "basset_hound_145.jpg\n",
      "basset_hound_146.jpg\n",
      "basset_hound_148.jpg\n",
      "basset_hound_149.jpg\n",
      "basset_hound_154.jpg\n",
      "basset_hound_161.jpg\n",
      "basset_hound_172.jpg\n",
      "basset_hound_173.jpg\n",
      "basset_hound_180.jpg\n",
      "basset_hound_180.jpg\n",
      "basset_hound_183.jpg\n",
      "beagle_103.jpg\n",
      "beagle_107.jpg\n",
      "beagle_115.jpg\n",
      "beagle_12.jpg\n",
      "beagle_131.jpg\n",
      "beagle_133.jpg\n",
      "beagle_14.jpg\n",
      "beagle_181.jpg\n",
      "beagle_182.jpg\n",
      "beagle_190.jpg\n",
      "beagle_192.jpg\n",
      "beagle_193.jpg\n",
      "Bengal_102.jpg\n",
      "Bengal_105.jpg\n",
      "Bengal_109.jpg\n",
      "Bengal_11.jpg\n",
      "Bengal_115.jpg\n",
      "Bengal_122.jpg\n",
      "Bengal_125.jpg\n",
      "Bengal_135.jpg\n",
      "Bengal_136.jpg\n",
      "Bengal_142.jpg\n",
      "Bengal_163.jpg\n",
      "Bengal_184.jpg\n",
      "Bengal_190.jpg\n",
      "Birman_109.jpg\n",
      "Birman_110.jpg\n",
      "Birman_128.jpg\n",
      "Birman_128.jpg\n",
      "Birman_129.jpg\n",
      "Birman_13.jpg\n",
      "Birman_134.jpg\n",
      "Birman_148.jpg\n",
      "Birman_158.jpg\n",
      "Birman_166.jpg\n",
      "Birman_168.jpg\n",
      "Birman_170.jpg\n",
      "Birman_178.jpg\n",
      "Birman_180.jpg\n",
      "Bombay_110.jpg\n",
      "Bombay_111.jpg\n",
      "Bombay_113.jpg\n",
      "Bombay_121.jpg\n",
      "Bombay_125.jpg\n",
      "Bombay_128.jpg\n",
      "Bombay_130.jpg\n",
      "Bombay_138.jpg\n",
      "Bombay_151.jpg\n",
      "Bombay_157.jpg\n",
      "Bombay_161.jpg\n",
      "Bombay_162.jpg\n",
      "Bombay_166.jpg\n",
      "Bombay_174.jpg\n",
      "Bombay_175.jpg\n",
      "Bombay_177.jpg\n",
      "Bombay_18.jpg\n",
      "Bombay_183.jpg\n",
      "Bombay_186.jpg\n",
      "Bombay_193.jpg\n",
      "boxer_105.jpg\n",
      "boxer_107.jpg\n",
      "boxer_11.jpg\n",
      "boxer_12.jpg\n",
      "boxer_135.jpg\n",
      "boxer_141.jpg\n",
      "boxer_147.jpg\n",
      "boxer_152.jpg\n",
      "boxer_158.jpg\n",
      "boxer_16.jpg\n",
      "boxer_188.jpg\n",
      "boxer_190.jpg\n",
      "British_Shorthair_10.jpg\n",
      "British_Shorthair_101.jpg\n",
      "British_Shorthair_104.jpg\n",
      "British_Shorthair_117.jpg\n",
      "British_Shorthair_118.jpg\n",
      "British_Shorthair_136.jpg\n",
      "British_Shorthair_140.jpg\n",
      "British_Shorthair_144.jpg\n",
      "British_Shorthair_153.jpg\n",
      "British_Shorthair_156.jpg\n",
      "British_Shorthair_201.jpg\n",
      "Egyptian_Mau_121.jpg\n",
      "Egyptian_Mau_125.jpg\n",
      "Egyptian_Mau_150.jpg\n",
      "Egyptian_Mau_165.jpg\n",
      "Egyptian_Mau_18.jpg\n",
      "Egyptian_Mau_182.jpg\n",
      "Egyptian_Mau_196.jpg\n",
      "english_cocker_spaniel_113.jpg\n",
      "english_cocker_spaniel_115.jpg\n",
      "english_cocker_spaniel_127.jpg\n",
      "english_cocker_spaniel_13.jpg\n",
      "english_cocker_spaniel_130.jpg\n",
      "english_cocker_spaniel_140.jpg\n",
      "english_cocker_spaniel_150.jpg\n",
      "english_cocker_spaniel_160.jpg\n",
      "english_cocker_spaniel_161.jpg\n",
      "english_cocker_spaniel_168.jpg\n",
      "english_cocker_spaniel_172.jpg\n",
      "english_cocker_spaniel_178.jpg\n",
      "english_cocker_spaniel_181.jpg\n",
      "english_cocker_spaniel_189.jpg\n",
      "english_setter_104.jpg\n",
      "english_setter_117.jpg\n",
      "english_setter_12.jpg\n",
      "english_setter_124.jpg\n",
      "english_setter_129.jpg\n",
      "english_setter_130.jpg\n",
      "english_setter_135.jpg\n",
      "english_setter_137.jpg\n",
      "english_setter_142.jpg\n",
      "english_setter_148.jpg\n",
      "english_setter_155.jpg\n",
      "english_setter_156.jpg\n",
      "english_setter_165.jpg\n",
      "english_setter_18.jpg\n",
      "german_shorthaired_102.jpg\n",
      "german_shorthaired_107.jpg\n",
      "german_shorthaired_119.jpg\n",
      "german_shorthaired_13.jpg\n",
      "german_shorthaired_136.jpg\n",
      "german_shorthaired_137.jpg\n",
      "german_shorthaired_139.jpg\n",
      "german_shorthaired_145.jpg\n",
      "german_shorthaired_154.jpg\n",
      "german_shorthaired_158.jpg\n",
      "german_shorthaired_165.jpg\n",
      "german_shorthaired_175.jpg\n",
      "great_pyrenees_104.jpg\n",
      "great_pyrenees_107.jpg\n",
      "great_pyrenees_114.jpg\n",
      "great_pyrenees_115.jpg\n",
      "great_pyrenees_119.jpg\n",
      "great_pyrenees_132.jpg\n",
      "great_pyrenees_141.jpg\n",
      "great_pyrenees_159.jpg\n",
      "great_pyrenees_165.jpg\n",
      "great_pyrenees_166.jpg\n",
      "great_pyrenees_170.jpg\n",
      "great_pyrenees_178.jpg\n",
      "havanese_116.jpg\n",
      "havanese_117.jpg\n",
      "havanese_118.jpg\n",
      "havanese_126.jpg\n",
      "havanese_132.jpg\n",
      "havanese_139.jpg\n",
      "havanese_146.jpg\n",
      "havanese_148.jpg\n",
      "havanese_162.jpg\n",
      "havanese_168.jpg\n",
      "havanese_17.jpg\n",
      "havanese_178.jpg\n",
      "japanese_chin_107.jpg\n",
      "japanese_chin_109.jpg\n",
      "japanese_chin_127.jpg\n",
      "japanese_chin_135.jpg\n",
      "japanese_chin_152.jpg\n",
      "japanese_chin_180.jpg\n",
      "japanese_chin_182.jpg\n",
      "keeshond_131.jpg\n",
      "keeshond_143.jpg\n",
      "keeshond_156.jpg\n",
      "leonberger_110.jpg\n",
      "leonberger_116.jpg\n",
      "leonberger_136.jpg\n",
      "leonberger_138.jpg\n",
      "leonberger_149.jpg\n",
      "leonberger_156.jpg\n",
      "leonberger_169.jpg\n",
      "leonberger_173.jpg\n",
      "leonberger_174.jpg\n",
      "leonberger_179.jpg\n",
      "leonberger_185.jpg\n",
      "leonberger_188.jpg\n",
      "Maine_Coon_124.jpg\n",
      "Maine_Coon_14.jpg\n",
      "Maine_Coon_155.jpg\n",
      "Maine_Coon_193.jpg\n",
      "miniature_pinscher_104.jpg\n",
      "miniature_pinscher_108.jpg\n",
      "miniature_pinscher_12.jpg\n",
      "miniature_pinscher_14.jpg\n",
      "newfoundland_10.jpg\n",
      "newfoundland_113.jpg\n",
      "newfoundland_117.jpg\n",
      "newfoundland_127.jpg\n",
      "newfoundland_134.jpg\n",
      "newfoundland_166.jpg\n",
      "newfoundland_178.jpg\n",
      "newfoundland_18.jpg\n",
      "Persian_115.jpg\n",
      "Persian_117.jpg\n",
      "Persian_158.jpg\n",
      "Persian_169.jpg\n",
      "Persian_195.jpg\n",
      "Persian_20.jpg\n",
      "pomeranian_18.jpg\n",
      "pug_104.jpg\n",
      "pug_11.jpg\n",
      "pug_111.jpg\n",
      "pug_119.jpg\n",
      "pug_137.jpg\n",
      "Ragdoll_103.jpg\n",
      "Ragdoll_119.jpg\n",
      "Ragdoll_137.jpg\n",
      "Ragdoll_139.jpg\n",
      "Ragdoll_168.jpg\n",
      "Ragdoll_174.jpg\n",
      "Ragdoll_186.jpg\n",
      "Ragdoll_196.jpg\n",
      "Russian_Blue_108.jpg\n",
      "Russian_Blue_112.jpg\n",
      "Russian_Blue_116.jpg\n",
      "Russian_Blue_117.jpg\n",
      "Russian_Blue_119.jpg\n",
      "Russian_Blue_123.jpg\n",
      "Russian_Blue_131.jpg\n",
      "Russian_Blue_143.jpg\n",
      "Russian_Blue_149.jpg\n",
      "Russian_Blue_170.jpg\n",
      "Russian_Blue_18.jpg\n",
      "Russian_Blue_186.jpg\n",
      "saint_bernard_116.jpg\n",
      "saint_bernard_122.jpg\n",
      "saint_bernard_131.jpg\n",
      "saint_bernard_135.jpg\n",
      "saint_bernard_138.jpg\n",
      "saint_bernard_145.jpg\n",
      "saint_bernard_148.jpg\n",
      "saint_bernard_154.jpg\n",
      "saint_bernard_157.jpg\n",
      "saint_bernard_16.jpg\n",
      "saint_bernard_17.jpg\n",
      "samoyed_102.jpg\n",
      "samoyed_127.jpg\n",
      "scottish_terrier_113.jpg\n",
      "scottish_terrier_135.jpg\n",
      "scottish_terrier_141.jpg\n",
      "scottish_terrier_142.jpg\n",
      "scottish_terrier_154.jpg\n",
      "scottish_terrier_169.jpg\n",
      "scottish_terrier_170.jpg\n",
      "scottish_terrier_174.jpg\n",
      "shiba_inu_103.jpg\n",
      "shiba_inu_113.jpg\n",
      "shiba_inu_161.jpg\n",
      "shiba_inu_164.jpg\n",
      "shiba_inu_177.jpg\n",
      "shiba_inu_194.jpg\n",
      "shiba_inu_194.jpg\n",
      "Siamese_100.jpg\n",
      "Siamese_102.jpg\n",
      "Siamese_103.jpg\n",
      "Siamese_106.jpg\n",
      "Siamese_108.jpg\n",
      "Siamese_117.jpg\n",
      "Siamese_125.jpg\n",
      "Siamese_130.jpg\n",
      "Siamese_133.jpg\n",
      "Siamese_135.jpg\n",
      "Siamese_137.jpg\n",
      "Siamese_141.jpg\n",
      "Siamese_151.jpg\n",
      "Siamese_164.jpg\n",
      "Siamese_167.jpg\n",
      "Siamese_171.jpg\n",
      "Siamese_172.jpg\n",
      "Siamese_175.jpg\n",
      "Siamese_178.jpg\n",
      "Siamese_180.jpg\n",
      "Siamese_182.jpg\n",
      "Siamese_184.jpg\n",
      "Siamese_188.jpg\n",
      "Siamese_199.jpg\n",
      "Siamese_204.jpg\n",
      "Siamese_205.jpg\n",
      "Sphynx_104.jpg\n",
      "Sphynx_12.jpg\n",
      "Sphynx_136.jpg\n",
      "Sphynx_141.jpg\n",
      "Sphynx_143.jpg\n",
      "Sphynx_151.jpg\n",
      "Sphynx_165.jpg\n",
      "Sphynx_177.jpg\n",
      "Sphynx_19.jpg\n",
      "Sphynx_192.jpg\n",
      "staffordshire_bull_terrier_102.jpg\n",
      "staffordshire_bull_terrier_137.jpg\n",
      "staffordshire_bull_terrier_138.jpg\n",
      "staffordshire_bull_terrier_14.jpg\n",
      "staffordshire_bull_terrier_145.jpg\n",
      "staffordshire_bull_terrier_16.jpg\n",
      "staffordshire_bull_terrier_160.jpg\n",
      "staffordshire_bull_terrier_174.jpg\n",
      "staffordshire_bull_terrier_179.jpg\n",
      "staffordshire_bull_terrier_195.jpg\n",
      "wheaten_terrier_106.jpg\n",
      "wheaten_terrier_118.jpg\n",
      "wheaten_terrier_137.jpg\n",
      "wheaten_terrier_162.jpg\n",
      "yorkshire_terrier_108.jpg\n",
      "yorkshire_terrier_113.jpg\n",
      "yorkshire_terrier_127.jpg\n",
      "yorkshire_terrier_161.jpg\n",
      "yorkshire_terrier_174.jpg\n",
      "yorkshire_terrier_178.jpg\n",
      "yorkshire_terrier_190.jpg\n",
      "Elapsed time: 5.2540 seconds\n",
      "Confusion Matrix: \n",
      "\n",
      "[TN: 1052.0, FP: 344.0]\n",
      "[FN: 2033.0, TP: 261.0]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "\n",
    "# initialize confusion matrix\n",
    "c_matrix = np.zeros((2, 2))\n",
    "\n",
    "image_folder = 'dataset-iiit-pet-master/images'\n",
    "xml_folder = 'dataset-iiit-pet-master/annotations/xmls'\n",
    "model = 'dog_detect/cascade.xml'\n",
    "\n",
    "img_files = os.listdir(image_folder)\n",
    " \n",
    "classifier = cv2.CascadeClassifier(model) \n",
    "\n",
    "# time loop\n",
    "start_time = time.time()\n",
    "for file in os.listdir(xml_folder):\n",
    "    \n",
    "    xml_file_path = os.path.join(xml_folder, file)\n",
    "    root = ET.parse(xml_file_path).getroot()\n",
    "    filename = root.find('filename').text\n",
    "    \n",
    "    if filename in os.listdir(image_folder):\n",
    "        img_file_path = os.path.join(image_folder, filename)\n",
    "        # confusion_matrix(c_matrix, xml, level_weights, objects)\n",
    "        img = cv2.imread(img_file_path)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Perform object detection\n",
    "        objects, reject_levels, level_weights = classifier.detectMultiScale3(gray,\n",
    "                                                scaleFactor=1.1, minNeighbors=50,\n",
    "                                                minSize=(75, 75), outputRejectLevels=True)\n",
    "        \n",
    "        confusion_matrix(c_matrix, xml_file_path, level_weights, objects, filename)\n",
    "    else:\n",
    "        print(f\"ERROR: image {img_file_path} not found.\")\n",
    "        \n",
    "# stop timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time/60:.4f} minutes\")\n",
    "\n",
    "# print resulting confusion matrix\n",
    "print(f\"Confusion Matrix: \\n\")\n",
    "print(f'[TN: {c_matrix[0][0]}, FP: {c_matrix[0][1]}]')\n",
    "print(f'[FN: {c_matrix[1][0]}, TP: {c_matrix[1][1]}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e28419-3903-49e5-9edd-6563e884284f",
   "metadata": {},
   "source": [
    "Display Image with Boundary Box and Detection Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "149a6746-fede-4a0c-893f-2990c3f12d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = 'yorkshire_terrier_184'\n",
    "image = f'dataset-iiit-pet-master/images/{img_name}.jpg'\n",
    "xml_path = f'dataset-iiit-pet-master/annotations/xmls/{img_name}.xml'\n",
    "model = 'dog_detect/cascade.xml'\n",
    "\n",
    "# read image\n",
    "img = cv2.imread(image)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Perform object detection\n",
    "objects, reject_levels, level_weights = classifier.detectMultiScale3(gray,\n",
    "                                        scaleFactor=1.1, minNeighbors=50,\n",
    "                                        minSize=(75, 75), outputRejectLevels=True)\n",
    "\n",
    "draw_boxes(img, xml_path, level_weights, objects)\n",
    "cv2.imshow('Object Detection', img)\n",
    "cv2.imwrite('parameters_check.jpg', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446c911-bf5a-4323-9043-eea5468ac7a2",
   "metadata": {},
   "source": [
    "Display Relavent Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4763c7e0-dc80-4838-ab46-e380bd4e356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.43140495867768597\n",
      "Recall: 0.11377506538796861\n",
      "Accuracy: 0.3558265582655827\n",
      "Specificity: 0.7535816618911175\n",
      "F1_score: 0.18006209037599172\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, accuracy, specificity, f1_score = get_metrics(c_matrix)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'F1_score: {f1_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
