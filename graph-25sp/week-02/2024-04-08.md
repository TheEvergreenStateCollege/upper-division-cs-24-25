
## Pair Programming with transport_graph.py

Learned PySpark DataFrames

https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.withCol

`.withColumn` creates a new dataframe with a new column appended to the end, with the given name.

Learned the builder pattern from FP
* Don't mutate the current data, but return a new version with the change already baked in
* If you see a lot of `.withColumn` `.drop` function calls indented,
* You are using the builder pattern, always creating data each time.
* At the end, your computer forgets it (its temporary and anonymous)
* If you want to save it, assign it to a variable.

```
reversed_rels = (rels.withColumn("newSrc", rels.dst)
    .withColumn("newDst", rels.src)
    .drop("dst", "src")
    .withColumnRenamed("newSrc", "src")
    .withColumnRenamed("newDst", "dst")
    .select("src", "dst", "relationship", "cost"))

relationships = rels.union(reversed_rels)
```

Resurrected our gitpod from last time.

Practiced git workflow `git status`, `git add <file>`, `git commit -m <message>`, `git push`

In gitpod, downloaded and ran (py)spark.

We discovered that GraphFrames package was missing, and it's not easy or clear to download it.

It should go in the `<SPARK_HOME>/jars` directory.

https://stackoverflow.com/questions/67936986/install-package-graphframes-using-spark-shell

There are some source code releases of GraphFrames as well, but it's not clear to me how to get the JAR file from that.

## Scala Syntax

Tell the language *what* you want, not *how* to do it.

```
def double(ints: List[Int]): List[Int] = {
  val buffer = new scala.collection.mutable.ListBuffer[Int]()
  for (i <- ints) {
    buffer += i * 2
  }
  buffer.toList
}

val newNumbers = double(oldNumbers)
```

From Chapter 6 FP Simplified.
